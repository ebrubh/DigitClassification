{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9db8f2",
   "metadata": {},
   "source": [
    "# Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25622a55",
   "metadata": {},
   "source": [
    "1) First, we need to import the required libraries and the digit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe222153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab896a",
   "metadata": {},
   "source": [
    "2) Seperation of the digit data into the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "446b90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_test = data[0:1000].T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n]\n",
    "X_test = X_test / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff392e",
   "metadata": {},
   "source": [
    "3) Writing the neccessery functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ee50b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    #setting the inital parameters\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    #Rectified Linear Units activation function\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    #derivative of the ReLu function\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    #Softmax activation function\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "    \n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    #Forward propagation \n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    #Backward propagation\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    #Parameters update\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d31569",
   "metadata": {},
   "source": [
    "4) Predictions and Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad702ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 100 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc7186",
   "metadata": {},
   "source": [
    "5) Testing the algoritm on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b967b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.28, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f232da",
   "metadata": {},
   "source": [
    "6) Functions for make and test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0d2092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8da73d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [4]\n",
      "Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(100, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc0700d",
   "metadata": {},
   "source": [
    "7) Testing the test data that the algoritm didn't see. The accuracy is 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32f4a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = make_predictions(X_test,W1, b1, W2, b2)\n",
    "get_accuracy(test_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0eb0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
